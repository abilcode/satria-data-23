{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn import linear_model, tree, discriminant_analysis, naive_bayes, ensemble, gaussian_process\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, FunctionTransformer, LabelEncoder, RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import log_loss, confusion_matrix\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 100)\n",
    "from pycaret.classification import *\n",
    "from function.data_engineering import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "\n",
    "    #GLM\n",
    "    linear_model.LogisticRegressionCV(),\n",
    "\n",
    "    #Navies Bayes\n",
    "    naive_bayes.BernoulliNB(),\n",
    "    naive_bayes.GaussianNB(),\n",
    "\n",
    "    #Discriminant Analysis\n",
    "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "\n",
    "    #Ensemble Methods\n",
    "    ensemble.AdaBoostClassifier(),\n",
    "    ensemble.BaggingClassifier(),\n",
    "    ensemble.ExtraTreesClassifier(),\n",
    "    ensemble.GradientBoostingClassifier(),\n",
    "    ensemble.RandomForestClassifier(),\n",
    "\n",
    "    #Gaussian Processes\n",
    "    gaussian_process.GaussianProcessClassifier(),\n",
    "\n",
    "    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
    "#     xgb.XGBClassifier()    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_algorithms(classifier_list, X, y):\n",
    "    # This function is adapted from https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling\n",
    "    # Cross validate model with Kfold stratified cross validation\n",
    "    kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    # Grab the cross validation scores for each algorithm\n",
    "    cv_results = [cross_val_score(classifier, X, y, scoring = \"accuracy\", cv = kfold) for classifier in classifier_list]\n",
    "    cv_means = [cv_result.mean() * -1 for cv_result in cv_results]\n",
    "    cv_std = [cv_result.std() for cv_result in cv_results]\n",
    "    algorithm_names = [alg.__class__.__name__ for alg in classifiers]\n",
    "\n",
    "    # Create a DataFrame of all the CV results\n",
    "    cv_results = pd.DataFrame({\n",
    "        \"Accuracy\": cv_means,\n",
    "        \"Accuracy Std\": cv_std,\n",
    "        \"Algorithm\": algorithm_names\n",
    "    }).sort_values(by='Accuracy')\n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('penyisihan-satria-data-itb-2023/train.csv')\n",
    "test = pd.read_csv('penyisihan-satria-data-itb-2023/test.csv')\n",
    "data.index = data.id\n",
    "test.index = test.id\n",
    "data = data.iloc[:,1:]\n",
    "test = test.iloc[:,1:]\n",
    "or_cols = [c for c in data.columns if c != 'target']\n",
    "int_cols = [c for c in data.columns if data[c].dtype=='int64' and c != 'target']\n",
    "float_cols = [c for c in data.columns if data[c].dtype=='float64' and c != 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data[or_cols])\n",
    "data[or_cols] = scaler.fit_transform(data[or_cols])\n",
    "test[or_cols] = scaler.transform(test[or_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hs</th>\n",
       "      <th>hst</th>\n",
       "      <th>hf</th>\n",
       "      <th>hc</th>\n",
       "      <th>hy</th>\n",
       "      <th>hr</th>\n",
       "      <th>b365h</th>\n",
       "      <th>b365d</th>\n",
       "      <th>bwh</th>\n",
       "      <th>bwd</th>\n",
       "      <th>iwh</th>\n",
       "      <th>iwd</th>\n",
       "      <th>psh</th>\n",
       "      <th>psd</th>\n",
       "      <th>whh</th>\n",
       "      <th>whd</th>\n",
       "      <th>vch</th>\n",
       "      <th>vcd</th>\n",
       "      <th>bb_mx_h</th>\n",
       "      <th>bb_av_h</th>\n",
       "      <th>bb_mx_d</th>\n",
       "      <th>bb_av_d</th>\n",
       "      <th>bb_ou</th>\n",
       "      <th>bb_mx_2_5</th>\n",
       "      <th>bb_av_2_5</th>\n",
       "      <th>bb_mx_2_5_1</th>\n",
       "      <th>bb_av_2_5_1</th>\n",
       "      <th>bb_ah</th>\n",
       "      <th>bb_a_hh</th>\n",
       "      <th>bb_mx_ahh</th>\n",
       "      <th>bb_av_ahh</th>\n",
       "      <th>bb_mx_aha</th>\n",
       "      <th>bb_av_aha</th>\n",
       "      <th>psch</th>\n",
       "      <th>pscd</th>\n",
       "      <th>target</th>\n",
       "      <th>hs_encode</th>\n",
       "      <th>hst_encode</th>\n",
       "      <th>hf_encode</th>\n",
       "      <th>hc_encode</th>\n",
       "      <th>hy_encode</th>\n",
       "      <th>hr_encode</th>\n",
       "      <th>bb_ou_encode</th>\n",
       "      <th>bb_ah_encode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040565</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.043108</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.049025</td>\n",
       "      <td>0.060773</td>\n",
       "      <td>0.042074</td>\n",
       "      <td>0.053289</td>\n",
       "      <td>0.044568</td>\n",
       "      <td>0.059406</td>\n",
       "      <td>0.045113</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.034918</td>\n",
       "      <td>0.044489</td>\n",
       "      <td>0.038055</td>\n",
       "      <td>0.048077</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.468421</td>\n",
       "      <td>0.491124</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.137184</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.522059</td>\n",
       "      <td>0.533835</td>\n",
       "      <td>0.196850</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.037553</td>\n",
       "      <td>0.041563</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.108333</td>\n",
       "      <td>0.071667</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.258333</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.138333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010027</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>0.279279</td>\n",
       "      <td>0.011813</td>\n",
       "      <td>0.314917</td>\n",
       "      <td>0.011252</td>\n",
       "      <td>0.265612</td>\n",
       "      <td>0.013370</td>\n",
       "      <td>0.306931</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.008915</td>\n",
       "      <td>0.011122</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.259615</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.168421</td>\n",
       "      <td>0.177515</td>\n",
       "      <td>0.357576</td>\n",
       "      <td>0.407942</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.419118</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.283465</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.196176</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.136667</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>0.301667</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.218333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010027</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.011529</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.015357</td>\n",
       "      <td>0.281768</td>\n",
       "      <td>0.009785</td>\n",
       "      <td>0.260616</td>\n",
       "      <td>0.011142</td>\n",
       "      <td>0.306931</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009287</td>\n",
       "      <td>0.010617</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.263112</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.163158</td>\n",
       "      <td>0.171598</td>\n",
       "      <td>0.378788</td>\n",
       "      <td>0.404332</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.519685</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.008017</td>\n",
       "      <td>0.267664</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.108333</td>\n",
       "      <td>0.098333</td>\n",
       "      <td>0.108333</td>\n",
       "      <td>0.301667</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.085000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038286</td>\n",
       "      <td>0.056429</td>\n",
       "      <td>0.039098</td>\n",
       "      <td>0.076577</td>\n",
       "      <td>0.049025</td>\n",
       "      <td>0.060773</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.064113</td>\n",
       "      <td>0.047911</td>\n",
       "      <td>0.084158</td>\n",
       "      <td>0.042607</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.033432</td>\n",
       "      <td>0.041962</td>\n",
       "      <td>0.059197</td>\n",
       "      <td>0.064685</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.321053</td>\n",
       "      <td>0.319527</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.238267</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.286765</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.417323</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.042616</td>\n",
       "      <td>0.055694</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.111667</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.301667</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065634</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.072682</td>\n",
       "      <td>0.018018</td>\n",
       "      <td>0.084465</td>\n",
       "      <td>0.016575</td>\n",
       "      <td>0.070939</td>\n",
       "      <td>0.018318</td>\n",
       "      <td>0.080780</td>\n",
       "      <td>0.019802</td>\n",
       "      <td>0.072682</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.055349</td>\n",
       "      <td>0.071284</td>\n",
       "      <td>0.009866</td>\n",
       "      <td>0.014860</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.668421</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.051515</td>\n",
       "      <td>0.061372</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.451128</td>\n",
       "      <td>0.259843</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.070042</td>\n",
       "      <td>0.017456</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043333</td>\n",
       "      <td>0.108333</td>\n",
       "      <td>0.128333</td>\n",
       "      <td>0.113333</td>\n",
       "      <td>0.131667</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.161667</td>\n",
       "      <td>0.218333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022334</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.026065</td>\n",
       "      <td>0.099099</td>\n",
       "      <td>0.025399</td>\n",
       "      <td>0.149171</td>\n",
       "      <td>0.024951</td>\n",
       "      <td>0.094921</td>\n",
       "      <td>0.027855</td>\n",
       "      <td>0.108911</td>\n",
       "      <td>0.026065</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.019316</td>\n",
       "      <td>0.025784</td>\n",
       "      <td>0.087385</td>\n",
       "      <td>0.095280</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.426316</td>\n",
       "      <td>0.449704</td>\n",
       "      <td>0.142424</td>\n",
       "      <td>0.162455</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.367647</td>\n",
       "      <td>0.360902</td>\n",
       "      <td>0.354331</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.019409</td>\n",
       "      <td>0.121363</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.136667</td>\n",
       "      <td>0.071667</td>\n",
       "      <td>0.143333</td>\n",
       "      <td>0.248333</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.005514</td>\n",
       "      <td>0.414414</td>\n",
       "      <td>0.008860</td>\n",
       "      <td>0.392265</td>\n",
       "      <td>0.005382</td>\n",
       "      <td>0.421316</td>\n",
       "      <td>0.006685</td>\n",
       "      <td>0.405941</td>\n",
       "      <td>0.006516</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.005561</td>\n",
       "      <td>0.383369</td>\n",
       "      <td>0.395105</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.136842</td>\n",
       "      <td>0.142012</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.501805</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.255639</td>\n",
       "      <td>0.456693</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.003376</td>\n",
       "      <td>0.570241</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.108333</td>\n",
       "      <td>0.301667</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.048333</td>\n",
       "      <td>0.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038286</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.042607</td>\n",
       "      <td>0.045045</td>\n",
       "      <td>0.051979</td>\n",
       "      <td>0.055249</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.050791</td>\n",
       "      <td>0.047911</td>\n",
       "      <td>0.029703</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.032318</td>\n",
       "      <td>0.041962</td>\n",
       "      <td>0.038055</td>\n",
       "      <td>0.042832</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.610526</td>\n",
       "      <td>0.627219</td>\n",
       "      <td>0.075758</td>\n",
       "      <td>0.083032</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.270677</td>\n",
       "      <td>0.448819</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.034599</td>\n",
       "      <td>0.051538</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076667</td>\n",
       "      <td>0.056667</td>\n",
       "      <td>0.111667</td>\n",
       "      <td>0.143333</td>\n",
       "      <td>0.131667</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.010632</td>\n",
       "      <td>0.337017</td>\n",
       "      <td>0.008317</td>\n",
       "      <td>0.309742</td>\n",
       "      <td>0.011142</td>\n",
       "      <td>0.306931</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.008172</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.260042</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.321053</td>\n",
       "      <td>0.313609</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>0.249097</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.360902</td>\n",
       "      <td>0.338583</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.008017</td>\n",
       "      <td>0.283458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.108333</td>\n",
       "      <td>0.118333</td>\n",
       "      <td>0.021667</td>\n",
       "      <td>0.131667</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.218333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027347</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.030075</td>\n",
       "      <td>0.099099</td>\n",
       "      <td>0.037212</td>\n",
       "      <td>0.093923</td>\n",
       "      <td>0.028376</td>\n",
       "      <td>0.084097</td>\n",
       "      <td>0.032312</td>\n",
       "      <td>0.089109</td>\n",
       "      <td>0.031078</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.023031</td>\n",
       "      <td>0.029828</td>\n",
       "      <td>0.073291</td>\n",
       "      <td>0.086538</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.378947</td>\n",
       "      <td>0.402367</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.184116</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.477941</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.244094</td>\n",
       "      <td>0.258333</td>\n",
       "      <td>0.024895</td>\n",
       "      <td>0.074813</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.136667</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.021667</td>\n",
       "      <td>0.248333</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.085000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           hs       hst        hf        hc        hy   hr     b365h  \\\n",
       "id                                                                     \n",
       "1    0.617647  0.400000  0.238095  0.555556  0.333333  0.0  0.040565   \n",
       "2    0.558824  0.333333  0.142857  0.444444  0.166667  0.0  0.010027   \n",
       "3    0.441176  0.400000  0.285714  0.388889  0.166667  0.0  0.010027   \n",
       "4    0.705882  0.733333  0.476190  0.333333  0.166667  0.0  0.038286   \n",
       "5    0.529412  0.400000  0.428571  0.166667  0.500000  0.0  0.065634   \n",
       "..        ...       ...       ...       ...       ...  ...       ...   \n",
       "596  0.411765  0.333333  0.238095  0.277778  0.000000  0.0  0.022334   \n",
       "597  0.558824  0.800000  0.142857  0.388889  0.166667  0.0  0.004558   \n",
       "598  0.382353  0.533333  0.476190  0.277778  0.500000  0.0  0.038286   \n",
       "599  0.617647  0.400000  0.380952  0.666667  0.500000  0.0  0.008660   \n",
       "600  0.852941  0.333333  0.333333  0.666667  0.000000  0.0  0.027347   \n",
       "\n",
       "        b365d       bwh       bwd       iwh       iwd       psh       psd  \\\n",
       "id                                                                          \n",
       "1    0.035714  0.043108  0.054054  0.049025  0.060773  0.042074  0.053289   \n",
       "2    0.250000  0.010526  0.279279  0.011813  0.314917  0.011252  0.265612   \n",
       "3    0.250000  0.011529  0.256757  0.015357  0.281768  0.009785  0.260616   \n",
       "4    0.056429  0.039098  0.076577  0.049025  0.060773  0.041096  0.064113   \n",
       "5    0.014286  0.072682  0.018018  0.084465  0.016575  0.070939  0.018318   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "596  0.085714  0.026065  0.099099  0.025399  0.149171  0.024951  0.094921   \n",
       "597  0.392857  0.005514  0.414414  0.008860  0.392265  0.005382  0.421316   \n",
       "598  0.035714  0.042607  0.045045  0.051979  0.055249  0.041096  0.050791   \n",
       "599  0.250000  0.010025  0.256757  0.010632  0.337017  0.008317  0.309742   \n",
       "600  0.071429  0.030075  0.099099  0.037212  0.093923  0.028376  0.084097   \n",
       "\n",
       "          whh       whd       vch       vcd   bb_mx_h   bb_av_h   bb_mx_d  \\\n",
       "id                                                                          \n",
       "1    0.044568  0.059406  0.045113  0.041667  0.034918  0.044489  0.038055   \n",
       "2    0.013370  0.306931  0.012030  0.250000  0.008915  0.011122  0.242424   \n",
       "3    0.011142  0.306931  0.012030  0.250000  0.009287  0.010617  0.242424   \n",
       "4    0.047911  0.084158  0.042607  0.062500  0.033432  0.041962  0.059197   \n",
       "5    0.080780  0.019802  0.072682  0.016667  0.055349  0.071284  0.009866   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "596  0.027855  0.108911  0.026065  0.083333  0.019316  0.025784  0.087385   \n",
       "597  0.006685  0.405941  0.006516  0.375000  0.005201  0.005561  0.383369   \n",
       "598  0.047911  0.029703  0.040100  0.041667  0.032318  0.041962  0.038055   \n",
       "599  0.011142  0.306931  0.010025  0.291667  0.008172  0.009100  0.260042   \n",
       "600  0.032312  0.089109  0.031078  0.075000  0.023031  0.029828  0.073291   \n",
       "\n",
       "      bb_av_d     bb_ou  bb_mx_2_5  bb_av_2_5  bb_mx_2_5_1  bb_av_2_5_1  \\\n",
       "id                                                                        \n",
       "1    0.048077  0.705882   0.468421   0.491124     0.121212     0.137184   \n",
       "2    0.259615  0.588235   0.168421   0.177515     0.357576     0.407942   \n",
       "3    0.263112  0.529412   0.163158   0.171598     0.378788     0.404332   \n",
       "4    0.064685  0.764706   0.321053   0.319527     0.212121     0.238267   \n",
       "5    0.014860  0.470588   0.668421   0.692308     0.051515     0.061372   \n",
       "..        ...       ...        ...        ...          ...          ...   \n",
       "596  0.095280  0.529412   0.426316   0.449704     0.142424     0.162455   \n",
       "597  0.395105  0.352941   0.136842   0.142012     0.424242     0.501805   \n",
       "598  0.042832  0.764706   0.610526   0.627219     0.075758     0.083032   \n",
       "599  0.269231  0.529412   0.321053   0.313609     0.218182     0.249097   \n",
       "600  0.086538  0.588235   0.378947   0.402367     0.166667     0.184116   \n",
       "\n",
       "     bb_ah   bb_a_hh  bb_mx_ahh  bb_av_ahh  bb_mx_aha  bb_av_aha      psch  \\\n",
       "id                                                                           \n",
       "1      0.8  0.409091   0.522059   0.533835   0.196850   0.216667  0.037553   \n",
       "2      0.6  0.227273   0.419118   0.421053   0.283465   0.300000  0.012658   \n",
       "3      0.9  0.272727   0.235294   0.210526   0.519685   0.533333  0.008017   \n",
       "4      0.5  0.454545   0.286765   0.285714   0.417323   0.441667  0.042616   \n",
       "5      0.6  0.500000   0.441176   0.451128   0.259843   0.291667  0.070042   \n",
       "..     ...       ...        ...        ...        ...        ...       ...   \n",
       "596    0.7  0.363636   0.367647   0.360902   0.354331   0.366667  0.019409   \n",
       "597    0.7  0.181818   0.264706   0.255639   0.456693   0.475000  0.003376   \n",
       "598    0.5  0.454545   0.264706   0.270677   0.448819   0.466667  0.034599   \n",
       "599    0.6  0.227273   0.352941   0.360902   0.338583   0.366667  0.008017   \n",
       "600    0.9  0.363636   0.477941   0.473684   0.244094   0.258333  0.024895   \n",
       "\n",
       "         pscd  target  hs_encode  hst_encode  hf_encode  hc_encode  hy_encode  \\\n",
       "id                                                                              \n",
       "1    0.041563       0   0.016667    0.108333   0.071667   0.075000   0.258333   \n",
       "2    0.196176       0   0.025000    0.136667   0.045000   0.091667   0.301667   \n",
       "3    0.267664       0   0.040000    0.108333   0.098333   0.108333   0.301667   \n",
       "4    0.055694       0   0.005000    0.025000   0.111667   0.110000   0.301667   \n",
       "5    0.017456       0   0.043333    0.108333   0.128333   0.113333   0.131667   \n",
       "..        ...     ...        ...         ...        ...        ...        ...   \n",
       "596  0.121363       1   0.070000    0.136667   0.071667   0.143333   0.248333   \n",
       "597  0.570241       1   0.025000    0.015000   0.045000   0.108333   0.301667   \n",
       "598  0.051538       1   0.076667    0.056667   0.111667   0.143333   0.131667   \n",
       "599  0.283458       0   0.016667    0.108333   0.118333   0.021667   0.131667   \n",
       "600  0.074813       0   0.001667    0.136667   0.105000   0.021667   0.248333   \n",
       "\n",
       "     hr_encode  bb_ou_encode  bb_ah_encode  \n",
       "id                                          \n",
       "1        0.955      0.070000      0.138333  \n",
       "2        0.955      0.140000      0.218333  \n",
       "3        0.955      0.146667      0.085000  \n",
       "4        0.955      0.053333      0.200000  \n",
       "5        0.955      0.161667      0.218333  \n",
       "..         ...           ...           ...  \n",
       "596      0.955      0.146667      0.183333  \n",
       "597      0.955      0.048333      0.183333  \n",
       "598      0.955      0.053333      0.200000  \n",
       "599      0.955      0.146667      0.218333  \n",
       "600      0.955      0.140000      0.085000  \n",
       "\n",
       "[600 rows x 44 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in int_cols:\n",
    "  tmp_train = freq_encoding(data, col)\n",
    "tmp_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Accuracy Std</th>\n",
       "      <th>Algorithm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.710000</td>\n",
       "      <td>0.048705</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.695000</td>\n",
       "      <td>0.051532</td>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.691667</td>\n",
       "      <td>0.050277</td>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.685000</td>\n",
       "      <td>0.052281</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.680000</td>\n",
       "      <td>0.017951</td>\n",
       "      <td>GaussianNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.671667</td>\n",
       "      <td>0.057155</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.668333</td>\n",
       "      <td>0.031798</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.648333</td>\n",
       "      <td>0.032232</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.648333</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.583333</td>\n",
       "      <td>0.017480</td>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.555000</td>\n",
       "      <td>0.056911</td>\n",
       "      <td>BernoulliNB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  Accuracy Std                      Algorithm\n",
       "3  -0.710000      0.048705     LinearDiscriminantAnalysis\n",
       "10 -0.695000      0.051532      GaussianProcessClassifier\n",
       "0  -0.691667      0.050277           LogisticRegressionCV\n",
       "8  -0.685000      0.052281     GradientBoostingClassifier\n",
       "2  -0.680000      0.017951                     GaussianNB\n",
       "5  -0.671667      0.057155             AdaBoostClassifier\n",
       "9  -0.668333      0.031798         RandomForestClassifier\n",
       "6  -0.648333      0.032232              BaggingClassifier\n",
       "7  -0.648333      0.046963           ExtraTreesClassifier\n",
       "4  -0.583333      0.017480  QuadraticDiscriminantAnalysis\n",
       "1  -0.555000      0.056911                    BernoulliNB"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm_results = find_best_algorithms(classifiers, tmp_train.loc[:,[i for i in tmp_train.columns if i !='target']], datmp_trainta.loc[:,'target'])\n",
    "algorithm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yt/n9_2kr5s6nx_5b2y_kx3mnnm0000gn/T/ipykernel_61329/2090915172.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best log loss: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mbest_lr_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    831\u001b[0m                         \u001b[0;34m**\u001b[0m\u001b[0mfit_and_score_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                     )\n\u001b[0;32m--> 833\u001b[0;31m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0m\u001b[1;32m    834\u001b[0m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     )\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    350\u001b[0m             )\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m         \u001b[0mtest_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mallowed_target_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype_of_target_y\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_target_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    677\u001b[0m                 \"Supported target types are: {}. Got {!r} instead.\".format(\n\u001b[1;32m    678\u001b[0m                     \u001b[0mallowed_target_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_of_target_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead."
     ]
    }
   ],
   "source": [
    "lr_grid = {\n",
    "    \"C\": [0.0001, 0.01, 0.05, 0.2, 1],\n",
    "    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\"]\n",
    "}\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "gs = GridSearchCV(LogisticRegression(), param_grid=lr_grid, cv=kfold, scoring='accuracy')\n",
    "gs.fit(data.iloc[:,:-1], data.iloc[:,-1])\n",
    "print(\"Best log loss: {}\".format(gs.best_score_ *-1))\n",
    "best_lr_params = gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_528d0_row9_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_528d0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_528d0_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_528d0_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_528d0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_528d0_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_528d0_row0_col1\" class=\"data row0 col1\" >42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_528d0_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_528d0_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_528d0_row1_col1\" class=\"data row1 col1\" >target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_528d0_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_528d0_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_528d0_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_528d0_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_528d0_row3_col0\" class=\"data row3 col0\" >Target mapping</td>\n",
       "      <td id=\"T_528d0_row3_col1\" class=\"data row3 col1\" >-1.0: 0, 1.0: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_528d0_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_528d0_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
       "      <td id=\"T_528d0_row4_col1\" class=\"data row4 col1\" >(600, 36)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_528d0_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_528d0_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_528d0_row5_col1\" class=\"data row5 col1\" >(600, 36)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_528d0_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_528d0_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_528d0_row6_col1\" class=\"data row6 col1\" >(420, 36)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_528d0_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_528d0_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_528d0_row7_col1\" class=\"data row7 col1\" >(180, 36)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_528d0_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_528d0_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_528d0_row8_col1\" class=\"data row8 col1\" >35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_528d0_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_528d0_row9_col0\" class=\"data row9 col0\" >Preprocess</td>\n",
       "      <td id=\"T_528d0_row9_col1\" class=\"data row9 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_528d0_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_528d0_row10_col0\" class=\"data row10 col0\" >Imputation type</td>\n",
       "      <td id=\"T_528d0_row10_col1\" class=\"data row10 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_528d0_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_528d0_row11_col0\" class=\"data row11 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_528d0_row11_col1\" class=\"data row11 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_528d0_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_528d0_row12_col0\" class=\"data row12 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_528d0_row12_col1\" class=\"data row12 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_528d0_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_528d0_row13_col0\" class=\"data row13 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_528d0_row13_col1\" class=\"data row13 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_528d0_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_528d0_row14_col0\" class=\"data row14 col0\" >Fold Number</td>\n",
       "      <td id=\"T_528d0_row14_col1\" class=\"data row14 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_528d0_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_528d0_row15_col0\" class=\"data row15 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_528d0_row15_col1\" class=\"data row15 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_528d0_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_528d0_row16_col0\" class=\"data row16 col0\" >Use GPU</td>\n",
       "      <td id=\"T_528d0_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_528d0_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_528d0_row17_col0\" class=\"data row17 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_528d0_row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_528d0_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_528d0_row18_col0\" class=\"data row18 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_528d0_row18_col1\" class=\"data row18 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_528d0_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_528d0_row19_col0\" class=\"data row19 col0\" >USI</td>\n",
       "      <td id=\"T_528d0_row19_col1\" class=\"data row19 col1\" >2369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fdb08c5aa00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pycaret.classification.oop.ClassificationExperiment at 0x7fdb08da55e0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = setup(data = data, target = 'target',fold=5,session_id = 42, )\n",
    "exp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>19:43:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Loading Dependencies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Compiling Library</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    \n",
       "                                                                    \n",
       "Initiated  . . . . . . . . . . . . . . . . . .              19:43:06\n",
       "Status     . . . . . . . . . . . . . . . . . .  Loading Dependencies\n",
       "Estimator  . . . . . . . . . . . . . . . . . .     Compiling Library"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ec5cc_row5_col0, #T_ec5cc_row5_col1, #T_ec5cc_row5_col2, #T_ec5cc_row5_col3, #T_ec5cc_row5_col4, #T_ec5cc_row5_col5, #T_ec5cc_row5_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ec5cc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ec5cc_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_ec5cc_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_ec5cc_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_ec5cc_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_ec5cc_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_ec5cc_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_ec5cc_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ec5cc_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ec5cc_row0_col0\" class=\"data row0 col0\" >0.7143</td>\n",
       "      <td id=\"T_ec5cc_row0_col1\" class=\"data row0 col1\" >0.7999</td>\n",
       "      <td id=\"T_ec5cc_row0_col2\" class=\"data row0 col2\" >0.6667</td>\n",
       "      <td id=\"T_ec5cc_row0_col3\" class=\"data row0 col3\" >0.7368</td>\n",
       "      <td id=\"T_ec5cc_row0_col4\" class=\"data row0 col4\" >0.7000</td>\n",
       "      <td id=\"T_ec5cc_row0_col5\" class=\"data row0 col5\" >0.4286</td>\n",
       "      <td id=\"T_ec5cc_row0_col6\" class=\"data row0 col6\" >0.4305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec5cc_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ec5cc_row1_col0\" class=\"data row1 col0\" >0.7143</td>\n",
       "      <td id=\"T_ec5cc_row1_col1\" class=\"data row1 col1\" >0.7642</td>\n",
       "      <td id=\"T_ec5cc_row1_col2\" class=\"data row1 col2\" >0.7143</td>\n",
       "      <td id=\"T_ec5cc_row1_col3\" class=\"data row1 col3\" >0.7143</td>\n",
       "      <td id=\"T_ec5cc_row1_col4\" class=\"data row1 col4\" >0.7143</td>\n",
       "      <td id=\"T_ec5cc_row1_col5\" class=\"data row1 col5\" >0.4286</td>\n",
       "      <td id=\"T_ec5cc_row1_col6\" class=\"data row1 col6\" >0.4286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec5cc_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ec5cc_row2_col0\" class=\"data row2 col0\" >0.6786</td>\n",
       "      <td id=\"T_ec5cc_row2_col1\" class=\"data row2 col1\" >0.7902</td>\n",
       "      <td id=\"T_ec5cc_row2_col2\" class=\"data row2 col2\" >0.5952</td>\n",
       "      <td id=\"T_ec5cc_row2_col3\" class=\"data row2 col3\" >0.7143</td>\n",
       "      <td id=\"T_ec5cc_row2_col4\" class=\"data row2 col4\" >0.6494</td>\n",
       "      <td id=\"T_ec5cc_row2_col5\" class=\"data row2 col5\" >0.3571</td>\n",
       "      <td id=\"T_ec5cc_row2_col6\" class=\"data row2 col6\" >0.3622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec5cc_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ec5cc_row3_col0\" class=\"data row3 col0\" >0.6548</td>\n",
       "      <td id=\"T_ec5cc_row3_col1\" class=\"data row3 col1\" >0.7364</td>\n",
       "      <td id=\"T_ec5cc_row3_col2\" class=\"data row3 col2\" >0.5952</td>\n",
       "      <td id=\"T_ec5cc_row3_col3\" class=\"data row3 col3\" >0.6757</td>\n",
       "      <td id=\"T_ec5cc_row3_col4\" class=\"data row3 col4\" >0.6329</td>\n",
       "      <td id=\"T_ec5cc_row3_col5\" class=\"data row3 col5\" >0.3095</td>\n",
       "      <td id=\"T_ec5cc_row3_col6\" class=\"data row3 col6\" >0.3117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec5cc_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ec5cc_row4_col0\" class=\"data row4 col0\" >0.7262</td>\n",
       "      <td id=\"T_ec5cc_row4_col1\" class=\"data row4 col1\" >0.7920</td>\n",
       "      <td id=\"T_ec5cc_row4_col2\" class=\"data row4 col2\" >0.6905</td>\n",
       "      <td id=\"T_ec5cc_row4_col3\" class=\"data row4 col3\" >0.7436</td>\n",
       "      <td id=\"T_ec5cc_row4_col4\" class=\"data row4 col4\" >0.7160</td>\n",
       "      <td id=\"T_ec5cc_row4_col5\" class=\"data row4 col5\" >0.4524</td>\n",
       "      <td id=\"T_ec5cc_row4_col6\" class=\"data row4 col6\" >0.4535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec5cc_level0_row5\" class=\"row_heading level0 row5\" >Mean</th>\n",
       "      <td id=\"T_ec5cc_row5_col0\" class=\"data row5 col0\" >0.6976</td>\n",
       "      <td id=\"T_ec5cc_row5_col1\" class=\"data row5 col1\" >0.7765</td>\n",
       "      <td id=\"T_ec5cc_row5_col2\" class=\"data row5 col2\" >0.6524</td>\n",
       "      <td id=\"T_ec5cc_row5_col3\" class=\"data row5 col3\" >0.7169</td>\n",
       "      <td id=\"T_ec5cc_row5_col4\" class=\"data row5 col4\" >0.6825</td>\n",
       "      <td id=\"T_ec5cc_row5_col5\" class=\"data row5 col5\" >0.3952</td>\n",
       "      <td id=\"T_ec5cc_row5_col6\" class=\"data row5 col6\" >0.3973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec5cc_level0_row6\" class=\"row_heading level0 row6\" >Std</th>\n",
       "      <td id=\"T_ec5cc_row6_col0\" class=\"data row6 col0\" >0.0267</td>\n",
       "      <td id=\"T_ec5cc_row6_col1\" class=\"data row6 col1\" >0.0234</td>\n",
       "      <td id=\"T_ec5cc_row6_col2\" class=\"data row6 col2\" >0.0490</td>\n",
       "      <td id=\"T_ec5cc_row6_col3\" class=\"data row6 col3\" >0.0238</td>\n",
       "      <td id=\"T_ec5cc_row6_col4\" class=\"data row6 col4\" >0.0346</td>\n",
       "      <td id=\"T_ec5cc_row6_col5\" class=\"data row6 col5\" >0.0535</td>\n",
       "      <td id=\"T_ec5cc_row6_col6\" class=\"data row6 col6\" >0.0525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fdb08d12f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc65fc03b49b44219b8427f2e03aadea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>19:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Searching Hyperparameters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            \n",
       "                                                                            \n",
       "Initiated  . . . . . . . . . . . . . . . . . .                      19:43:09\n",
       "Status     . . . . . . . . . . . . . . . . . .     Searching Hyperparameters\n",
       "Estimator  . . . . . . . . . . . . . . . . . .  Linear Discriminant Analysis"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_27916_row5_col0, #T_27916_row5_col1, #T_27916_row5_col2, #T_27916_row5_col3, #T_27916_row5_col4, #T_27916_row5_col5, #T_27916_row5_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_27916\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_27916_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_27916_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_27916_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_27916_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_27916_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_27916_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_27916_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_27916_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_27916_row0_col0\" class=\"data row0 col0\" >0.7381</td>\n",
       "      <td id=\"T_27916_row0_col1\" class=\"data row0 col1\" >0.7727</td>\n",
       "      <td id=\"T_27916_row0_col2\" class=\"data row0 col2\" >0.5476</td>\n",
       "      <td id=\"T_27916_row0_col3\" class=\"data row0 col3\" >0.8846</td>\n",
       "      <td id=\"T_27916_row0_col4\" class=\"data row0 col4\" >0.6765</td>\n",
       "      <td id=\"T_27916_row0_col5\" class=\"data row0 col5\" >0.4762</td>\n",
       "      <td id=\"T_27916_row0_col6\" class=\"data row0 col6\" >0.5150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27916_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_27916_row1_col0\" class=\"data row1 col0\" >0.7381</td>\n",
       "      <td id=\"T_27916_row1_col1\" class=\"data row1 col1\" >0.8101</td>\n",
       "      <td id=\"T_27916_row1_col2\" class=\"data row1 col2\" >0.7619</td>\n",
       "      <td id=\"T_27916_row1_col3\" class=\"data row1 col3\" >0.7273</td>\n",
       "      <td id=\"T_27916_row1_col4\" class=\"data row1 col4\" >0.7442</td>\n",
       "      <td id=\"T_27916_row1_col5\" class=\"data row1 col5\" >0.4762</td>\n",
       "      <td id=\"T_27916_row1_col6\" class=\"data row1 col6\" >0.4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27916_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_27916_row2_col0\" class=\"data row2 col0\" >0.6786</td>\n",
       "      <td id=\"T_27916_row2_col1\" class=\"data row2 col1\" >0.7942</td>\n",
       "      <td id=\"T_27916_row2_col2\" class=\"data row2 col2\" >0.5714</td>\n",
       "      <td id=\"T_27916_row2_col3\" class=\"data row2 col3\" >0.7273</td>\n",
       "      <td id=\"T_27916_row2_col4\" class=\"data row2 col4\" >0.6400</td>\n",
       "      <td id=\"T_27916_row2_col5\" class=\"data row2 col5\" >0.3571</td>\n",
       "      <td id=\"T_27916_row2_col6\" class=\"data row2 col6\" >0.3656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27916_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_27916_row3_col0\" class=\"data row3 col0\" >0.6905</td>\n",
       "      <td id=\"T_27916_row3_col1\" class=\"data row3 col1\" >0.7341</td>\n",
       "      <td id=\"T_27916_row3_col2\" class=\"data row3 col2\" >0.5714</td>\n",
       "      <td id=\"T_27916_row3_col3\" class=\"data row3 col3\" >0.7500</td>\n",
       "      <td id=\"T_27916_row3_col4\" class=\"data row3 col4\" >0.6486</td>\n",
       "      <td id=\"T_27916_row3_col5\" class=\"data row3 col5\" >0.3810</td>\n",
       "      <td id=\"T_27916_row3_col6\" class=\"data row3 col6\" >0.3922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27916_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_27916_row4_col0\" class=\"data row4 col0\" >0.6786</td>\n",
       "      <td id=\"T_27916_row4_col1\" class=\"data row4 col1\" >0.7398</td>\n",
       "      <td id=\"T_27916_row4_col2\" class=\"data row4 col2\" >0.5952</td>\n",
       "      <td id=\"T_27916_row4_col3\" class=\"data row4 col3\" >0.7143</td>\n",
       "      <td id=\"T_27916_row4_col4\" class=\"data row4 col4\" >0.6494</td>\n",
       "      <td id=\"T_27916_row4_col5\" class=\"data row4 col5\" >0.3571</td>\n",
       "      <td id=\"T_27916_row4_col6\" class=\"data row4 col6\" >0.3622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27916_level0_row5\" class=\"row_heading level0 row5\" >Mean</th>\n",
       "      <td id=\"T_27916_row5_col0\" class=\"data row5 col0\" >0.7048</td>\n",
       "      <td id=\"T_27916_row5_col1\" class=\"data row5 col1\" >0.7702</td>\n",
       "      <td id=\"T_27916_row5_col2\" class=\"data row5 col2\" >0.6095</td>\n",
       "      <td id=\"T_27916_row5_col3\" class=\"data row5 col3\" >0.7607</td>\n",
       "      <td id=\"T_27916_row5_col4\" class=\"data row5 col4\" >0.6717</td>\n",
       "      <td id=\"T_27916_row5_col5\" class=\"data row5 col5\" >0.4095</td>\n",
       "      <td id=\"T_27916_row5_col6\" class=\"data row5 col6\" >0.4224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27916_level0_row6\" class=\"row_heading level0 row6\" >Std</th>\n",
       "      <td id=\"T_27916_row6_col0\" class=\"data row6 col0\" >0.0276</td>\n",
       "      <td id=\"T_27916_row6_col1\" class=\"data row6 col1\" >0.0297</td>\n",
       "      <td id=\"T_27916_row6_col2\" class=\"data row6 col2\" >0.0777</td>\n",
       "      <td id=\"T_27916_row6_col3\" class=\"data row6 col3\" >0.0630</td>\n",
       "      <td id=\"T_27916_row6_col4\" class=\"data row6 col4\" >0.0382</td>\n",
       "      <td id=\"T_27916_row6_col5\" class=\"data row6 col5\" >0.0551</td>\n",
       "      <td id=\"T_27916_row6_col6\" class=\"data row6 col6\" >0.0621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fdb19ef4f70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "#lda\n",
    "lda = create_model('lda')\n",
    "tuned_lda = tune_model(lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c11720c7eb46c8928d1efa189e3112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Plot Type:', icons=('',), options=(('Pipeline Plot', 'pipelinâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABWAAAAH2CAYAAAD+hyWQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgvElEQVR4nO3df4zldX3v8dcYCDuzbTSBtEuIcattPgakaBcLCkYvbWwUa9qA5aZNS0hIq4SqoZhrvc3dJje1V4FGTTasbfpjjWmjQYhNsE1NxHsFSiULayq1HxfbaW5wL0JT8McOP0bm/nHONONhRuY7O+8zO7OPRzKZPd/z+Z7z+eud2ed853tmlpaWAgAAAADA5nvRVm8AAAAAAGCnEmABAAAAAIoIsAAAAAAARQRYAAAAAIAiAiwAAAAAQBEBFgAAAACgiAALAAAAAFBEgAUAAAAAKCLAAgAAAAAUOW2jJ7bWzkhyOMn1vfcvrrHmNUkOJjk/yUNJ3tl7P7zR9wQAAAAA2E42dAVsa21Xkr9Kct4PWbM7yeeSfCnJviT3JrlzfBwAAAAAYMcbHGBba+cmuS/JK15g6VVJFpK8r/f+tSTvTfKdJO8Y+p4AAAAAANvRRq6AfWOSu5K87gXWXZzk7t77UpKMv9+zjvMAAAAAAHaEwfeA7b3fuvzv1toPW3p2Rvd9XenRJK9az/scPnz4iSRnJDk2bIcAAAAAABt2dpKn9+3b95LNeLENfwjXOswleXri2NMZRdX1OCPJriQ/sZmbAgAAAACYlsoA+1SeH1vPSHJ8necfS/ITe/fuzezs7KZuDNjeFhYWMj8/H/MBWMlsANZiPgCrMRuAtRw9ejSLi4ub9lf5lQH2kSR7Jo7tycBbCszOzmZubm7TNgXsHOYDsBqzAViL+QCsxmwAJs3MzGzq623kQ7jW674kr2+tzSTJ+Psl4+MAAAAAADvepgbY1tqe1trydfu3JXlJko+01s5N8pEku5N8ejPfEwAAAADgZLXZV8AeS3JVkvTev53kbUnekORwkouTvLX3/r1Nfk8AAAAAgJPSCd0Dtvc+8wKPv5zkZ07kPQAAAAAAtqvKe8ACAAAAAJzSBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQ5begJrbVdSQ4kuSLJQpKbe++3rLH2l5N8MMlLkxxJ8u7e+wMb3i0AAAAAwDaykStgb0pyYZLLklyXZH9r7crJRa2185L8ZZI/THJBRgH2ztba3IZ3CwAAAACwjQwKsK213UmuTfKe3vsDvfc7knw4yfWrLH9zkod675/ovX8jye8m2ZPk3BPcMwAAAADAtjD0CtgLkpye5N4Vx+5OclFrbfK1/j3Jea21S8bPXZPk20m+sdHNAgAAAABsJ0PvAXt2ksd778+sOPZokl1Jzkzy2Irjn0ry9owC7feTPJfk8t77fwx5w4WFhYFbBHa65blgPgArmQ3AWswHYDVmA7CWpaWlTX29oQF2LsnTE8eWH58xcfzMjG45cH2S+5K8K8mft9Z+pvf+rfW+4fz8/MAtAqcK8wFYjdkArMV8AFZjNgDVhgbYp/L80Lr8+PjE8Q8l+cfe+4Ekaa39ZpKvZXQrgg+t9w337t2b2dnZgdsEdrKFhYXMz8+bD8APMBuAtZgPwGrMBmAtR48ezeLi4qa93tAA+0iSs1prp/Xel3exJ8lCkicm1u5L8rHlB73351prX0nysiFvODs7m7m5uYHbBE4F5gOwGrMBWIv5AKzGbAAmzczMbOrrDf0QriNJnk1y8Ypjlya5v/f+3MTabyY5d+JYS/KvA98TAAAAAGBbGnQFbO/9eGvtUJKDrbVrkpyT5MaMbiuQ1tqeJE/23heS/EmSv2it3Z/k75Ncm9HVr4c2cf8AAAAAACetoVfAJskNSQ4nuSvJgST7e++3j587luSqJOm9fyqjD+D6QJIHk1yS5LIhH8AFAAAAALCdDb0HbHrvx5NcPf6afG5m4vGfJvnTDe8OAAAAAGAb28gVsAAAAAAArIMACwAAAABQRIAFAAAAACgiwAIAAAAAFBFgAQAAAACKCLAAAAAAAEUEWAAAAACAIgIsAAAAAEARARYAAAAAoIgACwAAAABQRIAFAAAAACgiwAIAAAAAFBFgAQAAAACKCLAAAAAAAEUEWAAAAACAIgIsAAAAAEARARYAAAAAoIgACwAAAABQRIAFAAAAACgiwAIAAAAAFBFgAQAAAACKCLAAAAAAAEUEWAAAAACAIgIsAAAAAEARARYAAAAAoIgACwAAAABQRIAFAAAAACgiwAIAAAAAFBFgAQAAAACKCLAAAAAAAEUEWAAAAACAIgIsAAAAAEARARYAAAAAoIgACwAAAABQRIAFAAAAACgiwAIAAAAAFBFgAQAAAACKCLAAAAAAAEUEWAAAAACAIgIsAAAAAEARARYAAAAAoIgACwAAAABQRIAFAAAAACgiwAIAAAAAFBFgAQAAAACKCLAAAAAAAEUEWAAAAACAIgIsAAAAAEARARYAAAAAoIgACwAAAABQRIAFAAAAACgiwAIAAAAAFBFgAQAAAACKCLAAAAAAAEUEWAAAAACAIgIsAAAAAEARARYAAAAAoIgACwAAAABQRIAFAAAAACgiwAIAAAAAFBFgAQAAAACKCLAAAAAAAEUEWAAAAACAIgIsAAAAAEARARYAAAAAoIgACwAAAABQRIAFAAAAACgiwAIAAAAAFBFgAQAAAACKCLAAAAAAAEUEWAAAAACAIgIsAAAAAEARARYAAAAAoIgACwAAAABQRIAFAAAAACgiwAIAAAAAFBFgAQAAAACKCLAAAAAAAEVOG3pCa21XkgNJrkiykOTm3vsta6w9P8mtSfYleTjJu3vvd218uwAAAAAA28dGroC9KcmFSS5Lcl2S/a21KycXtdZenOTzSf4pyflJbk9yR2vtxza+XQAAAACA7WNQgG2t7U5ybZL39N4f6L3fkeTDSa5fZfnVSb6b5F2994d77/uTHM0o3gIAAAAA7HhDb0FwQZLTk9y74tjdSf57a+1FvffnVhx/U5LP9t6/v3yg9/7ajW4UAAAAAGC7GRpgz07yeO/9mRXHHk2yK8mZSR5bcfzlSb7cWvvjJG9PMp/kd3rv9wx5w4WFhYFbBHa65blgPgArmQ3AWswHYDVmA7CWpaWlTX29oQF2LsnTE8eWH58xcfxHkrw/yUeTvCXJf03yd621V/be/+9633B+fn7gFoFThfkArMZsANZiPgCrMRuAakMD7FN5fmhdfnx84vhikgfH935Nkgdba29O8utJPrjeN9y7d29mZ2cHbhPYyRYWFjI/P28+AD/AbADWYj4AqzEbgLUcPXo0i4uLm/Z6QwPsI0nOaq2d1ntf3sWeJAtJnphYeyzJP08c+3qSlw55w9nZ2czNzQ3cJnAqMB+A1ZgNwFrMB2A1ZgMwaWZmZlNf70UD1x9J8mySi1ccuzTJ/RMfwJUk92X0oV0rvTKje8ECAAAAAOx4g66A7b0fb60dSnKwtXZNknOS3JjkmiRpre1J8mTvfSHJwSS/3Vr7/SSfTPIbGX0w1yc3b/sAAAAAACevoVfAJskNSQ4nuSvJgST7e++3j587luSqJOm9/1uSX0jyi0m+Ov5+ee/9kRPdNAAAAADAdjD0HrDpvR9PcvX4a/K5mYnH9yTZt+HdAQAAAABsYxu5AhYAAAAAgHUQYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUOS0oSe01nYlOZDkiiQLSW7uvd/yAufsTfLVJG/rvX9x+DYBAAAAALafjVwBe1OSC5NcluS6JPtba1e+wDm3Jtm9gfcCAAAAANi2Bl0B21rbneTaJG/pvT+Q5IHW2nlJrk9y2xrn/FqSHz3RjQIAAAAAbDdDr4C9IMnpSe5dcezuJBe11p73Wq21M5N8OMlvbXiHAAAAAADb1NB7wJ6d5PHe+zMrjj2aZFeSM5M8NrH+j5Ic6r0/1Frb0AYXFhY2dB6wcy3PBfMBWMlsANZiPgCrMRuAtSwtLW3q6w0NsHNJnp44tvz4jJUHW2s/n+TSJK/a2NZG5ufnT+R0YAczH4DVmA3AWswHYDVmA1BtaIB9KhOhdcXj48sHWmuzST6e5Lre+wn9Kmnv3r2ZnZ09kZcAdpiFhYXMz8+bD8APMBuAtZgPwGrMBmAtR48ezeLi4qa93tAA+0iSs1prp/Xel3exJ8lCkidWrPvZJC9P8pmJWw/8TWvtUO/9net9w9nZ2czNzQ3cJnAqMB+A1ZgNwFrMB2A1ZgMwaWZmZlNfb2iAPZLk2SQXZ/ThW8noNgP3996fW7Huy0l+auLco0muTfL54dsEAAAAANh+BgXY3vvx1tqhJAdba9ckOSfJjUmuSZLW2p4kT45vO/DwynPHV8I+0nv/1mZsHAAAAADgZPeiDZxzQ5LDSe5KciDJ/t777ePnjiW5apP2BgAAAACwrQ29BUF678eTXD3+mnxuzRsk/LDnAAAAAAB2oo1cAQsAAAAAwDoIsAAAAAAARQRYAAAAAIAiAiwAAAAAQBEBFgAAAACgiAALAAAAAFBEgAUAAAAAKCLAAgAAAAAUEWABAAAAAIoIsAAAAAAARQRYAAAAAIAiAiwAAAAAQBEBFgAAAACgiAALAAAAAFBEgAUAAAAAKCLAAgAAAAAUEWABAAAAAIoIsAAAAAAARQRYAAAAAIAiAiwAAAAAQBEBFgAAAACgiAALAAAAAFBEgAUAAAAAKCLAAgAAAAAUEWABAAAAAIoIsAAAAAAARQRYAAAAAIAiAiwAAAAAQBEBFgAAAACgiAALAAAAAFBEgAUAAAAAKCLAAgAAAAAUEWABAAAAAIoIsAAAAAAARQRYAAAAAIAiAiwAAAAAQBEBFgAAAACgiAALAAAAAFBEgAUAAAAAKCLAAgAAAAAUEWABAAAAAIoIsAAAAAAARQRYAAAAAIAiAiwAAAAAQBEBFgAAAACgiAALAAAAAFBEgAUAAAAAKCLAAgAAAAAUEWABAAAAAIoIsAAAAAAARQRYAAAAAIAiAiwAAAAAQBEBFgAAAACgiAALAAAAAFBEgAUAAAAAKCLAAgAAAAAUEWABAAAAAIoIsAAAAAAARQRYAAAAAIAiAiwAAAAAQBEBFgAAAACgiAALAAAAAFBEgAUAAAAAKCLAAgAAAAAUEWABAAAAAIoIsAAAAAAARQRYAAAAAIAiAiwAAAAAQBEBFgAAAACgiAALAAAAAFBEgAUAAAAAKCLAAgAAAAAUEWABAAAAAIoIsAAAAAAARQRYAAAAAIAiAiwAAAAAQBEBFgAAAACgiAALAAAAAFDktKEntNZ2JTmQ5IokC0lu7r3fssbay5P8QZKfTPIvSX6v9/7XG98uAAAAAMD2sZErYG9KcmGSy5Jcl2R/a+3KyUWttZ9OcnuSP0vy6iQfT3Jba+2CDe8WAAAAAGAbGXQFbGttd5Jrk7yl9/5Akgdaa+cluT7JbRPLfzXJF3rvHxs/fri19vYkv5LkKye2bQAAAACAk9/QK2AvSHJ6kntXHLs7yUWttcnXOpTk/au8xosHvicAAAAAwLY09B6wZyd5vPf+zIpjjybZleTMJI8tH+y9f23lieMrZX8uycGNbRUAAAAAYHsZGmDnkjw9cWz58RlrndRaOyvJZ5Lck+SzQ95wYWFhyHLgFLA8F8wHYCWzAViL+QCsxmwA1rK0tLSprzc0wD6V54fW5cfHVzuhtfbjST6f0e0Oruy9PzfkDefn5wduEThVmA/AaswGYC3mA7AaswGoNjTAPpLkrNbaab33xfGxPUkWkjwxubi1dk6SL4wfvqn3/tjkmheyd+/ezM7ODj0N2MEWFhYyPz9vPgA/wGwA1mI+AKsxG4C1HD16NIuLiy+8cJ2GBtgjSZ5NcnFGH76VJJcmuX/yytbW2u4kf5vkuST/pff+/zaywdnZ2czNzW3kVGCHMx+A1ZgNwFrMB2A1ZgMwaWZmZlNfb1CA7b0fb60dSnKwtXZNknOS3JjkmiRpre1J8mTvfSHJB5K8IsmbVjyXJAu99yc3Z/sAAAAAACevF23gnBuSHE5yV5IDSfb33m8fP3csyVXjf1+RZDbJP4yPL3999EQ2DAAAAACwXQy9BUF678eTXD3+mnxuZsW/X3liWwMAAAAA2N42cgUsAAAAAADrIMACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKCIAAsAAAAAUESABQAAAAAoIsACAAAAABQRYAEAAAAAigiwAAAAAABFBFgAAAAAgCICLAAAAABAEQEWAAAAAKDIaUNPaK3tSnIgyRVJFpLc3Hu/ZY21r0lyMMn5SR5K8s7e++GNbxcAAAAAYPvYyBWwNyW5MMllSa5Lsr+1duXkotba7iSfS/KlJPuS3JvkzvFxAAAAAIAdb1CAHcfTa5O8p/f+QO/9jiQfTnL9KsuvyugK2ff13r+W5L1JvpPkHSe0YwAAAACAbWLoFbAXJDk9o6tZl92d5KLW2uRrXZzk7t77UpKMv9+T5HUb3CsAAAAAwLYy9B6wZyd5vPf+zIpjjybZleTMJI9NrH1o4vxHk7xqwHvl6NGjmZmZGbhNYCdbWlpKYj4AP8hsANZiPgCrMRuAtTz77LPJuE1uhqEBdi7J0xPHlh+fsc61k+vW8nSSLC4uHhuyQeDUsbi4uNVbAE5CZgOwFvMBWI3ZAKzi7Dy/a27Y0AD7VJ4fUJcfH1/n2sl1q9q3b99LBu4NAAAAAOCkMvQesI8kOau1tjLc7snow7aeWGXtnolje5K4ohUAAAAAOCUMDbBHkjyb0QdsLbs0yf299+cm1t6X5PWttZkkGX+/ZHwcAAAAAGDHGxRge+/HkxxKcrC19trW2i8luTHJR5OktbantTY7Xn5bkpck+Uhr7dwkH0myO8mnN2XnAAAAAAAnuaFXwCbJDUkOJ7kryYEk+3vvt4+fO5bkqiTpvX87yduSvGG8/uIkb+29f+9ENw0AAAAAsB3MLC0tbfUeAAAAAAB2pI1cAQsAAAAAwDoIsAAAAAAARQRYAAAAAIAip23lm7fWdmX0QV5XJFlIcnPv/ZY11r4mycEk5yd5KMk7e++Hp7VXYLoGzofLk/xBkp9M8i9Jfq/3/tfT2iswPUNmw4pz9ib5apK39d6/WL1HYGsM/Nnh/CS3JtmX5OEk7+693zWtvQLTM3A2/HKSDyZ5aZIjGc2GB6a0VWALtNbOSHI4yfVr/V9hM5rkVl8Be1OSC5NcluS6JPtba1dOLmqt7U7yuSRfyuiHpHuT3Dk+DuxM650PP53k9iR/luTVST6e5LbW2gXT2yowReuaDRNuTeJnBtj51vuzw4uTfD7JP2X0H6nbk9zRWvuxKe4VmJ71zobzkvxlkj9MckFGAfbO1trc9LYKTNP4FzR/leS8H7JmU5rklgXY8UavTfKe3vsDvfc7knw4yfWrLL8qo99Uva/3/rUk703ynSTvmNJ2gSkaOB9+NckXeu8f670/3Hs/kOSuJL8yvR0D0zBwNiyf82tJfnRKWwS2yMD5cHWS7yZ51/hnh/1JjmYUaIAdZOBseHOSh3rvn+i9fyPJ7ybZk+TcqW0YmJrW2rlJ7kvyihdYuilNciuvgL0gyekZleNldye5qLU2ua+Lk9zde19KkvH3e5K8bhobBaZuyHw4lOT9q7zGi4v2BmydIbMhrbUzM/pP1m9NZ3vAFhoyH96U5LO99+8vH+i9v7b3/rnyXQLTNmQ2/HuS81prl4yfuybJt5N8Yyo7BabtjRldvPVCbXFTmuRW3gP27CSP996fWXHs0SS7kpyZ5LGJtQ9NnP9okleV7hDYKuueD+PfQP2n8Z8O/VxG92cBdpYhPzskyR8lOdR7f6i1NqUtAltkyHx4eZIvt9b+OMnbk8wn+Z3e+z1T2iswPUNmw6cymgl3J/l+kueSXN57/48p7RWYot77rcv/foH/K2xKk9zKK2Dnkjw9cWz58RnrXDu5DtgZhsyH/9RaOyvJZzL6bdRna7YGbKF1z4bW2s8nuTTJ/5zCvoCtN+Rnhx/J6K9njiV5S5L/neTvWmsvLd0hsBWGzIYzM7rlwPVJLkryiSR/7v7QcMrblCa5lQH2qTx/s8uPj69z7eQ6YGcYMh+SJK21H0/yhYzm2pW99+fqtgdskXXNhtbabEYfyHdd731hSnsDttaQnx0WkzzYe9/fe3+w9/7fknw9ya8X7xGYviGz4UNJ/rH3fmD86ea/meR7Gd2KADh1bUqT3MoA+0iSs1prK2+DsCejG9s+scraPRPH9mT0W2tg5xkyH9JaOyfJ/8loCL6p9z75Z8jAzrDe2fCzGf2J8Wdaa99trX13fPxvWmtuTwI705CfHY4l+eeJY19P4gpY2HmGzIZ9Sb6y/GB8QcdXkryseI/AyW1TmuRWBtgjSZ7N6Ga2yy5Ncv8qV67dl+T1rbWZJBl/v2R8HNh5jmSd82H8yaZ/m9E9mt7Ye//mtDYJTN2RrG82fDnJTyV59YqvZPQpyP+jeI/A1jiSYf+3uGDi2CszuhcssLMcyfpnwzeTnDtxrCX517LdAdvBpjTJLfsQrt778dbaoSQHW2vXJDknyY0ZX97fWtuT5Mnxnw7eluR/JflIa+3jGX2a8e4kn96SzQOlBs6HDyR5RUafaLz8XJIs9N6fnPbegToDZ8PDK88d31j/kd77t6a7a2AaBs6Hg0l+u7X2+0k+meQ3Mrpq/pNbsXegzsDZ8CdJ/qK1dn+Sv8/oF7cvS3JoSzYPbJmKJrmVV8AmyQ1JDie5K8mBJPt777ePnzuW5Kok6b1/O8nbkrxhvP7iJG/tvX9v6jsGpmVd8yHJFUlmk/zD+Pjy10enultgWtY7G4BTz3r/b/FvSX4hyS8m+er4++W990emvmNgGtY7Gz6V0QdwfSDJgxld4XaZX97CKWnTm+TM0tLSZm8SAAAAAIBs/RWwAAAAAAA7lgALAAAAAFBEgAUAAAAAKCLAAgAAAAAUEWABAAAAAIoIsAAAAAAARQRYAAAAAIAiAiwAAAAAQBEBFgAAAACgiAALAAAAAFBEgAUAAAAAKCLAAgAAAAAU+f840rr2KVQUiwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1700x600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(tuned_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>19:44:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Loading Dependencies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Compiling Library</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    \n",
       "                                                                    \n",
       "Initiated  . . . . . . . . . . . . . . . . . .              19:44:17\n",
       "Status     . . . . . . . . . . . . . . . . . .  Loading Dependencies\n",
       "Estimator  . . . . . . . . . . . . . . . . . .     Compiling Library"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c40ba_row5_col0, #T_c40ba_row5_col1, #T_c40ba_row5_col2, #T_c40ba_row5_col3, #T_c40ba_row5_col4, #T_c40ba_row5_col5, #T_c40ba_row5_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c40ba\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c40ba_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_c40ba_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_c40ba_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_c40ba_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_c40ba_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_c40ba_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_c40ba_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c40ba_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c40ba_row0_col0\" class=\"data row0 col0\" >0.7619</td>\n",
       "      <td id=\"T_c40ba_row0_col1\" class=\"data row0 col1\" >0.8005</td>\n",
       "      <td id=\"T_c40ba_row0_col2\" class=\"data row0 col2\" >0.7143</td>\n",
       "      <td id=\"T_c40ba_row0_col3\" class=\"data row0 col3\" >0.7895</td>\n",
       "      <td id=\"T_c40ba_row0_col4\" class=\"data row0 col4\" >0.7500</td>\n",
       "      <td id=\"T_c40ba_row0_col5\" class=\"data row0 col5\" >0.5238</td>\n",
       "      <td id=\"T_c40ba_row0_col6\" class=\"data row0 col6\" >0.5262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c40ba_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c40ba_row1_col0\" class=\"data row1 col0\" >0.6905</td>\n",
       "      <td id=\"T_c40ba_row1_col1\" class=\"data row1 col1\" >0.7965</td>\n",
       "      <td id=\"T_c40ba_row1_col2\" class=\"data row1 col2\" >0.7381</td>\n",
       "      <td id=\"T_c40ba_row1_col3\" class=\"data row1 col3\" >0.6739</td>\n",
       "      <td id=\"T_c40ba_row1_col4\" class=\"data row1 col4\" >0.7045</td>\n",
       "      <td id=\"T_c40ba_row1_col5\" class=\"data row1 col5\" >0.3810</td>\n",
       "      <td id=\"T_c40ba_row1_col6\" class=\"data row1 col6\" >0.3827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c40ba_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c40ba_row2_col0\" class=\"data row2 col0\" >0.6905</td>\n",
       "      <td id=\"T_c40ba_row2_col1\" class=\"data row2 col1\" >0.8050</td>\n",
       "      <td id=\"T_c40ba_row2_col2\" class=\"data row2 col2\" >0.6190</td>\n",
       "      <td id=\"T_c40ba_row2_col3\" class=\"data row2 col3\" >0.7222</td>\n",
       "      <td id=\"T_c40ba_row2_col4\" class=\"data row2 col4\" >0.6667</td>\n",
       "      <td id=\"T_c40ba_row2_col5\" class=\"data row2 col5\" >0.3810</td>\n",
       "      <td id=\"T_c40ba_row2_col6\" class=\"data row2 col6\" >0.3849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c40ba_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c40ba_row3_col0\" class=\"data row3 col0\" >0.6429</td>\n",
       "      <td id=\"T_c40ba_row3_col1\" class=\"data row3 col1\" >0.7506</td>\n",
       "      <td id=\"T_c40ba_row3_col2\" class=\"data row3 col2\" >0.5714</td>\n",
       "      <td id=\"T_c40ba_row3_col3\" class=\"data row3 col3\" >0.6667</td>\n",
       "      <td id=\"T_c40ba_row3_col4\" class=\"data row3 col4\" >0.6154</td>\n",
       "      <td id=\"T_c40ba_row3_col5\" class=\"data row3 col5\" >0.2857</td>\n",
       "      <td id=\"T_c40ba_row3_col6\" class=\"data row3 col6\" >0.2887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c40ba_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c40ba_row4_col0\" class=\"data row4 col0\" >0.7024</td>\n",
       "      <td id=\"T_c40ba_row4_col1\" class=\"data row4 col1\" >0.8231</td>\n",
       "      <td id=\"T_c40ba_row4_col2\" class=\"data row4 col2\" >0.6429</td>\n",
       "      <td id=\"T_c40ba_row4_col3\" class=\"data row4 col3\" >0.7297</td>\n",
       "      <td id=\"T_c40ba_row4_col4\" class=\"data row4 col4\" >0.6835</td>\n",
       "      <td id=\"T_c40ba_row4_col5\" class=\"data row4 col5\" >0.4048</td>\n",
       "      <td id=\"T_c40ba_row4_col6\" class=\"data row4 col6\" >0.4077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c40ba_level0_row5\" class=\"row_heading level0 row5\" >Mean</th>\n",
       "      <td id=\"T_c40ba_row5_col0\" class=\"data row5 col0\" >0.6976</td>\n",
       "      <td id=\"T_c40ba_row5_col1\" class=\"data row5 col1\" >0.7951</td>\n",
       "      <td id=\"T_c40ba_row5_col2\" class=\"data row5 col2\" >0.6571</td>\n",
       "      <td id=\"T_c40ba_row5_col3\" class=\"data row5 col3\" >0.7164</td>\n",
       "      <td id=\"T_c40ba_row5_col4\" class=\"data row5 col4\" >0.6840</td>\n",
       "      <td id=\"T_c40ba_row5_col5\" class=\"data row5 col5\" >0.3952</td>\n",
       "      <td id=\"T_c40ba_row5_col6\" class=\"data row5 col6\" >0.3980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c40ba_level0_row6\" class=\"row_heading level0 row6\" >Std</th>\n",
       "      <td id=\"T_c40ba_row6_col0\" class=\"data row6 col0\" >0.0381</td>\n",
       "      <td id=\"T_c40ba_row6_col1\" class=\"data row6 col1\" >0.0241</td>\n",
       "      <td id=\"T_c40ba_row6_col2\" class=\"data row6 col2\" >0.0614</td>\n",
       "      <td id=\"T_c40ba_row6_col3\" class=\"data row6 col3\" >0.0443</td>\n",
       "      <td id=\"T_c40ba_row6_col4\" class=\"data row6 col4\" >0.0442</td>\n",
       "      <td id=\"T_c40ba_row6_col5\" class=\"data row6 col5\" >0.0762</td>\n",
       "      <td id=\"T_c40ba_row6_col6\" class=\"data row6 col6\" >0.0760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fdae99020a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "055c06e847514823870bd335d3cb1d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>19:44:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Searching Hyperparameters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         \n",
       "                                                                         \n",
       "Initiated  . . . . . . . . . . . . . . . . . .                   19:44:21\n",
       "Status     . . . . . . . . . . . . . . . . . .  Searching Hyperparameters\n",
       "Estimator  . . . . . . . . . . . . . . . . . .        Logistic Regression"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_84ee0_row5_col0, #T_84ee0_row5_col1, #T_84ee0_row5_col2, #T_84ee0_row5_col3, #T_84ee0_row5_col4, #T_84ee0_row5_col5, #T_84ee0_row5_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_84ee0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_84ee0_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_84ee0_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_84ee0_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_84ee0_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_84ee0_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_84ee0_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_84ee0_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_84ee0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_84ee0_row0_col0\" class=\"data row0 col0\" >0.7500</td>\n",
       "      <td id=\"T_84ee0_row0_col1\" class=\"data row0 col1\" >0.7993</td>\n",
       "      <td id=\"T_84ee0_row0_col2\" class=\"data row0 col2\" >0.7143</td>\n",
       "      <td id=\"T_84ee0_row0_col3\" class=\"data row0 col3\" >0.7692</td>\n",
       "      <td id=\"T_84ee0_row0_col4\" class=\"data row0 col4\" >0.7407</td>\n",
       "      <td id=\"T_84ee0_row0_col5\" class=\"data row0 col5\" >0.5000</td>\n",
       "      <td id=\"T_84ee0_row0_col6\" class=\"data row0 col6\" >0.5013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84ee0_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_84ee0_row1_col0\" class=\"data row1 col0\" >0.6786</td>\n",
       "      <td id=\"T_84ee0_row1_col1\" class=\"data row1 col1\" >0.7993</td>\n",
       "      <td id=\"T_84ee0_row1_col2\" class=\"data row1 col2\" >0.7143</td>\n",
       "      <td id=\"T_84ee0_row1_col3\" class=\"data row1 col3\" >0.6667</td>\n",
       "      <td id=\"T_84ee0_row1_col4\" class=\"data row1 col4\" >0.6897</td>\n",
       "      <td id=\"T_84ee0_row1_col5\" class=\"data row1 col5\" >0.3571</td>\n",
       "      <td id=\"T_84ee0_row1_col6\" class=\"data row1 col6\" >0.3581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84ee0_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_84ee0_row2_col0\" class=\"data row2 col0\" >0.7024</td>\n",
       "      <td id=\"T_84ee0_row2_col1\" class=\"data row2 col1\" >0.7993</td>\n",
       "      <td id=\"T_84ee0_row2_col2\" class=\"data row2 col2\" >0.6667</td>\n",
       "      <td id=\"T_84ee0_row2_col3\" class=\"data row2 col3\" >0.7179</td>\n",
       "      <td id=\"T_84ee0_row2_col4\" class=\"data row2 col4\" >0.6914</td>\n",
       "      <td id=\"T_84ee0_row2_col5\" class=\"data row2 col5\" >0.4048</td>\n",
       "      <td id=\"T_84ee0_row2_col6\" class=\"data row2 col6\" >0.4058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84ee0_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_84ee0_row3_col0\" class=\"data row3 col0\" >0.6548</td>\n",
       "      <td id=\"T_84ee0_row3_col1\" class=\"data row3 col1\" >0.7500</td>\n",
       "      <td id=\"T_84ee0_row3_col2\" class=\"data row3 col2\" >0.5952</td>\n",
       "      <td id=\"T_84ee0_row3_col3\" class=\"data row3 col3\" >0.6757</td>\n",
       "      <td id=\"T_84ee0_row3_col4\" class=\"data row3 col4\" >0.6329</td>\n",
       "      <td id=\"T_84ee0_row3_col5\" class=\"data row3 col5\" >0.3095</td>\n",
       "      <td id=\"T_84ee0_row3_col6\" class=\"data row3 col6\" >0.3117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84ee0_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_84ee0_row4_col0\" class=\"data row4 col0\" >0.6905</td>\n",
       "      <td id=\"T_84ee0_row4_col1\" class=\"data row4 col1\" >0.8192</td>\n",
       "      <td id=\"T_84ee0_row4_col2\" class=\"data row4 col2\" >0.6190</td>\n",
       "      <td id=\"T_84ee0_row4_col3\" class=\"data row4 col3\" >0.7222</td>\n",
       "      <td id=\"T_84ee0_row4_col4\" class=\"data row4 col4\" >0.6667</td>\n",
       "      <td id=\"T_84ee0_row4_col5\" class=\"data row4 col5\" >0.3810</td>\n",
       "      <td id=\"T_84ee0_row4_col6\" class=\"data row4 col6\" >0.3849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84ee0_level0_row5\" class=\"row_heading level0 row5\" >Mean</th>\n",
       "      <td id=\"T_84ee0_row5_col0\" class=\"data row5 col0\" >0.6952</td>\n",
       "      <td id=\"T_84ee0_row5_col1\" class=\"data row5 col1\" >0.7934</td>\n",
       "      <td id=\"T_84ee0_row5_col2\" class=\"data row5 col2\" >0.6619</td>\n",
       "      <td id=\"T_84ee0_row5_col3\" class=\"data row5 col3\" >0.7103</td>\n",
       "      <td id=\"T_84ee0_row5_col4\" class=\"data row5 col4\" >0.6843</td>\n",
       "      <td id=\"T_84ee0_row5_col5\" class=\"data row5 col5\" >0.3905</td>\n",
       "      <td id=\"T_84ee0_row5_col6\" class=\"data row5 col6\" >0.3924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84ee0_level0_row6\" class=\"row_heading level0 row6\" >Std</th>\n",
       "      <td id=\"T_84ee0_row6_col0\" class=\"data row6 col0\" >0.0316</td>\n",
       "      <td id=\"T_84ee0_row6_col1\" class=\"data row6 col1\" >0.0230</td>\n",
       "      <td id=\"T_84ee0_row6_col2\" class=\"data row6 col2\" >0.0486</td>\n",
       "      <td id=\"T_84ee0_row6_col3\" class=\"data row6 col3\" >0.0368</td>\n",
       "      <td id=\"T_84ee0_row6_col4\" class=\"data row6 col4\" >0.0353</td>\n",
       "      <td id=\"T_84ee0_row6_col5\" class=\"data row6 col5\" >0.0632</td>\n",
       "      <td id=\"T_84ee0_row6_col6\" class=\"data row6 col6\" >0.0629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fdb19e6c3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "#lda\n",
    "lr = create_model('lr')\n",
    "tuned_lr = tune_model(lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
